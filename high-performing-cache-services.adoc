= Lab1 - Creating High-performing Cacheable Service
:experimental:

In this lab, we’ll develop 5 microservices into the cloud-native appliation architecture. These cloud-native applications will have transactions with multiple datasources such as *PostgreSQL* and *MongoDB*. Especially, we will learn how to configure datasources easily using *Quarkus Extensions*. In the end, we will optimize *data transaction performance* of the shopping cart service thru integrating with a *Cache(Data Grid) server* to increase end users’(customers) satification. And there’s more fun facts how easy it is to deploy applications on OpenShift 4 via *oc* command line tool.

=== Goals of this lab

The goal is to develop advanced cloud-native applications on *Red Hat Runtimes* and deploy them on *OpenShift 4* including _single sign-on access management_ and _distributed cache manageemnt_. After this lab, you should end up with something like:

image::lab1-goal.png[goal, 700]

=== 1. Deploying Inventory Service

_Inventory Service_ serves inventory and availability data for retail products. Lets’s go through quickly how the inventory service works and built on *Quarkus* Java runtimes. Go to _Explorer: /projects_ in _CodeReady Workspaces_ Web IDE and expand *inventory-service* directory.

image::codeready-workspace-inventory-project.png[inventory_service, 700]

While the code is surprisingly simple, under the hood this is using:

* *RESTEasy* to expose the REST endpoints
* *Hibernate ORM* with Panache to perform the CRUD operations on the database
* *Maven* Java project structure

_Hibernate ORM_ is the de facto JPA implementation and offers you the full breadth of an Object Relational Mapper. It makes complex mappings possible, but it does not make simple and common mappings trivial. Hibernate ORM with Panache focuses on making your entities trivial and fun to write in Quarkus.

When you open `Inventory.java` in `src/main/java/com/redhat/cloudnative/` as below, you will understand how easy to create a domain model using Quarkus extension(https://quarkus.io/guides/hibernate-orm-panache-guide[Hibernate ORM with Panache^]).

[source,java]
----
@Entity
@Cacheable
public class Inventory extends PanacheEntity {

    public String itemId;
    public String location;
    public int quantity;
    public String link;

    public Inventory() {

    }

}
----

* By extending _PanacheEntity_ in your entities, you will get an ID field that is auto-generated. If you require a custom ID strategy, you can extend _PanacheEntityBase_ instead and handle the ID yourself.
* By using Use public fields, there is no need for functionless getters and setters (those that simply get or set the field). You simply refer to fields like Inventory.location without the need to write a Inventory.getLocation() implementation. Panache will auto-generate any getters and setters you do not write, or you can develop your own getters/setters that do more than get/set,
which will be called when the field is accessed directly.

The PanacheEntity superclass comes with lots of super useful static methods and you can add your own in your derived entity class, and much like traditional object-oriented programming it’s natural and recommended to place custom queries as close to the entity as possible, ideally within the entity definition itself. Users can just start using your entity Inventory by typing
Inventory, and getting completion for all the operations in a single place.

When an entity is annotated with _@Cacheable_, all its field values are cached except for collections and relations to other entities. This means the entity can be loaded without querying the database, but be careful as it implies the loaded entity might not reflect recent changes in the database.

Next, let’s find out how _inventory service_ exposes _RESTful APIs_ on Quarkus. Open `InventoryResource.java` in `src/main/java/com/redhat/cloudnative/` and you will see the following code sniffet.

The REST services defines two endpoints:

* `/api/inventory` that is accessible via `HTTP GET` which will return all known product Inventory entities as JSON
* `/api/inventory/<itemId>` that is accessible via `HTTP GET` at for example `/inventory/329199` with the last path parameter
being the location which we want to check its inventory status.

image::inventoryResource.png[inventory_service, 700]

*In Development*, we will configure to use local _in-memory H2 database_ for local testing, as defined in `src/main/resources/application.properties`:

[source,none]
----
quarkus.datasource.url=jdbc:h2:file://projects/database.db
quarkus.datasource.driver=org.h2.Driver
quarkus.datasource.username=inventory
quarkus.datasource.password=mysecretpassword
quarkus.datasource.max-size=8
quarkus.datasource.min-size=2
quarkus.hibernate-orm.database.generation=drop-and-create
quarkus.hibernate-orm.log.sql=false
----

Let’s run the inventory application locally using `maven plugin command` via CodeReady Workspaces Terminal:

[source,sh,role="copypaste"]
----
mvn clean compile quarkus:dev -f $CHE_PROJECTS_ROOT/cloud-native-workshop-v2m4-labs/inventory-service
----

You should see a bunch of log output that ends with:

[source,console]
----
2020-03-19 00:55:12,598 INFO  [io.agr.pool] (main) Datasource '<default>': Initial size smaller than min. Connections will be created when necessary
2020-03-19 00:55:12,887 INFO  [io.quarkus] (main) inventory 1.0-SNAPSHOT (running on Quarkus xx.xx.xx) started in 3.166s. Listening on: http://0.0.0.0:8080
2020-03-19 00:55:12,890 INFO  [io.quarkus] (main) Profile dev activated. Live Coding activated.
2020-03-19 00:55:12,890 INFO  [io.quarkus] (main) Installed features: [agroal, cdi, hibernate-orm, hibernate-orm-panache, jdbc-h2, narayana-jta, resteasy, resteasy-jsonb, smallrye-health]
----

CodeReady will also detect that the Quarkus app opens port `5005` (for debugging) and `8080` (for web requests). Do not open port 5005, but when prompted, open the port `8080`, which opens a small web browser in CodeReady:

You should see a bunch of log output and Theia popup shows the endpoint for your local application. Click on `Open Link` then you
will see *Coolstore Inventory* page on you left side. `Close` the popup window.

image::open-port.png[Inventory RESTful Service, 700]

You should see the inventory web frontend directly in CodeReady (you may need to click the _reload_ icon):

image::inventory-codeready.png[Inventory RESTful Service, 700]

Open a *new* CodeReady Workspaces Terminal:

image::codeready-workspace-terminal.png[Inventory RESTful Service, 700]

and invoke the RESTful endpoint using the following CURL commands.

[source,sh,role="copypaste"]
----
curl http://localhost:8080/api/inventory | jq
----

The output looks like:

[source,json]
----
  ...
  {
    "id": 7,
    "itemId": "444435",
    "link": "http://maps.google.com/?q=Paris",
    "location": "Paris",
    "quantity": 600
  },
  {
    "id": 8,
    "itemId": "444437",
    "link": "http://maps.google.com/?q=Tokyo",
    "location": "Tokyo",
    "quantity": 230
  }
----

Be sure to terminate the running Quarkus development via kbd:[CTRL+C] (or kbd:[Command+C] on Mac OS).

*In production*, the inventory service will connect to _PostgeSQL_ on OpenShift cluster.

We will use _Quarkus extension_ to add *PostgreSQL JDBC Driver*. Go back to CodeReady Workspaces Terminal and run the following
maven plugin:

[source,sh,role="copypaste"]
----
mvn quarkus:add-extension -Dextensions="jdbc-postgresql" -f $CHE_PROJECTS_ROOT/cloud-native-workshop-v2m4-labs/inventory-service
----

You should see in the output:

[source,console]
----
✅ Adding extension io.quarkus:quarkus-jdbc-postgresql
----

Package the application via running the following maven plugin in CodeReady Workspaces Terminal:

[source,sh,role="copypaste"]
----
mvn clean compile package -DskipTests -f $CHE_PROJECTS_ROOT/cloud-native-workshop-v2m4-labs/inventory-service
----

[NOTE]
====
You should `SKIP` the Unit test because you don’t have PostgreSQL database in local environment.
====

Although your Eclipse Che workspace is running on the Kubernetes cluster, it’s running with a default restricted _Service Account_ that prevents you from creating most resource types. If you’ve completed other modules, you’re probably already logged in, but let’s login again: open a Terminal and issue the following command:

[source,sh,role="copypaste"]
----
oc login https://$KUBERNETES_SERVICE_HOST:$KUBERNETES_SERVICE_PORT --insecure-skip-tls-verify=true
----

Enter your username and password assigned to you:

* Username: `{{ USER_ID }}`
* Password: `{{ OPENSHIFT_USER_PASSWORD }}`

You should see something like this (the project names may be different):

[source,none]
----
Login successful.

You have access to the following projects and can switch between them with 'oc project <projectname>':

  * {{ USER_ID }}-bookinfo
    {{ USER_ID }}-catalog
    {{ USER_ID }}-cloudnative-pipeline
    {{ USER_ID }}-cloudnativeapps
    {{ USER_ID }}-inventory
    {{ USER_ID }}-istio-system

Using project "{{ USER_ID }}-bookinfo".
Welcome! See 'oc help' to get started.
----

First, open a new brower with the {{ CONSOLE_URL }}[OpenShift web console^]:

image::openshift_login.png[openshift_login, 700]

Login using:

* Username: `{{ USER_ID }}`
* Password: `{{ OPENSHIFT_USER_PASSWORD }}`

[NOTE]
====
When you access the OpenShift web console or other URLs via _HTTPS_ protocol, you will see browser warnings like `Your > Connection is not secure` since this workshop uses self-signed certificates (which you should not do in production!).
For example, if you’re using *Chrome*, you will see the following screen.

Click on `Advanced` then, you can access the HTTPS page when you click on `Proceed to...`!!!
====

image::browser_warning.png[warning, 700]

Other browsers have similar procedures to accept the security exception.

You will see a list of projects to which you have access:

image::openshift_landing.png[openshift_landing, 700]

[NOTE]
====
The project displayed in the landing page depends on which labs you will run today. If you will develop
`Service Mesh and Identity` then you will see pre-created projects as the above screeenshot.
====

Open the {{ CONSOLE_URL }}/topology/ns/{{ USER_ID }}-cloudnativeapps[Topology View^].

Our production inventory microservice will use an external database (PostgreSQL) to house inventory data. First, deploy a new
instance of PostgreSQL. Click *+Add* on the left, on the _Database_ box on the *{{ USER_ID }}-cloudnativeapps* project overview:

image::db.png[db, 700]

Type in `postgres` in the search box, and click on the *PostgreSQL (ephemeral)*:

image::db-postgres.png[db, 700]

Click on *Instantiate Template* and fill in the following fields, leaving the others as their default values:

* *Namespace*: _choose `{{ USER_ID }}-cloudnativeapps` for the first Namespace. Leave the second one as `openshift`_
* *Database Service Name*: `inventory-database`
* *PostgreSQL Connection Username*: `inventory`
* *PostgreSQL Connection Password*: `mysecretpassword`
* *PostgreSQL Database Name*: `inventory`

image::db-postgres-inventory-values.png[db, 700]

This will deploy the database to our new project. Click on the {{ CONSOLE_URL }}/topology/ns/{{ USER_ID }}-cloudnativeapps[Topology View^] to see it:

image::inventory-database-deployment.png[inventory_db_deployments, 700]

Create a build configuration for your application using OpenJDK base container image in OpenShift:

[source,sh,role="copypaste"]
----
oc project {{ USER_ID }}-cloudnativeapps && oc new-build registry.access.redhat.com/redhat-openjdk-18/openjdk18-openshift:1.5 --binary --name=inventory -l app=inventory
----

[NOTE]
====
This build uses the new https://access.redhat.com/documentation/en-us/red_hat_jboss_middleware_for_openshift/3/html/red_hat_java_s2i_for_openshift/index[Red Hat OpenJDK Container Image^], providing foundational software needed to run Java applications, while staying at
a reasonable size.
====

Start and watch the build, which will take about minutes to complete:

[source,sh,role="copypaste"]
----
oc start-build inventory --from-file $CHE_PROJECTS_ROOT/cloud-native-workshop-v2m4-labs/inventory-service/target/*-runner.jar --follow
----

Once the build is done, we’ll deploy it as an OpenShift application and override the Postgres URL to specify our production Postgres credentials:

[source,sh,role="copypaste"]
----
oc new-app inventory && oc expose svc/inventory && \
oc label dc/inventory app.kubernetes.io/part-of=inventory app.openshift.io/runtime=java --overwrite && \
oc label dc/inventory-database app.kubernetes.io/part-of=inventory app.openshift.io/runtime=postgresql --overwrite && \
oc annotate dc/inventory app.openshift.io/connects-to=inventory-database --overwrite && \
oc annotate dc/inventory app.openshift.io/vcs-uri=https://github.com/RedHat-Middleware-Workshops/cloud-native-workshop-v2m4-labs.git --overwrite && \
oc annotate dc/inventory app.openshift.io/vcs-ref=ocp-4.3 --overwrite
----

Back on the {{ CONSOLE_URL }}/topology/ns/{{ USER_ID }}-cloudnativeapps[Topology View^], make sure it's done deploying (dark blue circle):

image::inventory_topology.png[inventory, 700]

Click on the small arrow icon as shown above and you will see inventories:

image::inventory_topology_openurl.png[inventory, 700]

So now `Inventory` service is deployed to OpenShift. You can also see it in the Project Status in the OpenShift Console with its single replica running in 1 pod, along with the Postgres database pod.

=== 2. Deploying Catalog Service

_Catalog Service_ serves products and prices for retail products. Lets’s go through quickly how the catalog service works and built on *Spring Boot* Java runtimes. Go to _Explorer: /projects_ in _CodeReady Workspaces_ Web IDE and expand *catalog-service* directory.

image::codeready-workspace-catalog-project.png[catalog, 700]

First of all, we won’t implement the catalog application to retrieve data because of all funtions are already built when we imported this project from Git server. There’re a few interesting things what we need to take a look at this Spring Boot
application before we will deploy it to OpenShift cluster.

This catalog service is not using the default BOM (Bill of material) that Spring Boot projects typically use. Instead, we are using a BOM provided by Red Hat as part of the http://snowdrop.me/[Snowdrop^] project.

[source,xml]
----
    <dependencyManagement>
        <dependencies>
            <dependency>
                <groupId>me.snowdrop</groupId>
                <artifactId>spring-boot-bom</artifactId>
                <version>2.1.6.SP3-redhat-00001</version>
                <type>pom</type>
                <scope>import</scope>
            </dependency>
            <dependency>
                <groupId>org.springframework.cloud</groupId>
                <artifactId>spring-cloud-dependencies</artifactId>
                <version>${spring-cloud.bom.version}</version>
                <type>pom</type>
                <scope>import</scope>
            </dependency>
        </dependencies>
    </dependencyManagement>
----

image::catalog-pom.png[catalog, 700]

Also, catalog service calls the inventory service that we deployed earlier using REST to retrieve the inventory status and include
that in the response. Open `CatalogService.java` in `src/main/java/com/redhat/coolstore/service` directory via Project Explorer
and how `read()` and `readAll()` method work:

image::catalog-service-codes.png[catalog, 700]

Build and deploy the project using the following command, which will use the maven plugin to deploy via CodeReady Workspaces Terminal:

[source,sh,role="copypaste"]
----
mvn clean package spring-boot:repackage -DskipTests -f $CHE_PROJECTS_ROOT/cloud-native-workshop-v2m4-labs/catalog-service
----

The build and deploy may take a minute or two. Wait for it to complete. You should see a `BUILD SUCCESS` at the end of the build output.

Our `production` catalog microservice will use an external database (PostgreSQL) to house inventory data. Visit the {{ CONSOLE_URL }}/topology/ns/{{ USER_ID }}-cloudnativeapps[Topology View^].

Click *+Add* on the left, on the _Database_ box on the project overview:

image::db.png[db, 700]

Type in `postgres` in the search box, and click on the *PostgreSQL (ephemeral)*:

image::db-postgres.png[db, 700]

Click on *Instantiate Template* and fill in the following fields, leaving the others as their default values:

* *Namespace*: _choose `{{ USER_ID }}-cloudnativeapps` for the first Namespace. Leave the second one as `openshift`_
* *Database Service Name*: `catalog-database`
* *PostgreSQL Connection Username*: `catalog`
* *PostgreSQL Connection Password*: `mysecretpassword`
* *PostgreSQL Database Name*: `catalog`

image::db-catalog-postgres-fields.png[db, 700]

This will deploy the database to our catalog project. Click on the {{ CONSOLE_URL }}/topology/ns/{{ USER_ID }}-cloudnativeapps[Topology View^] to see it.

Create a build configuration for your application using OpenJDK base container image in OpenShift:

[source, properties, role="copypaste"]
----
oc new-build registry.access.redhat.com/redhat-openjdk-18/openjdk18-openshift:1.5 --binary --name=catalog -l app=catalog
----

Start and watch the build, which will take about minutes to complete:

[source,sh,role="copypaste"]
----
oc start-build catalog --from-file=$CHE_PROJECTS_ROOT/cloud-native-workshop-v2m4-labs/catalog-service/target/catalog-1.0.0-SNAPSHOT.jar --follow
----

Once the build is done, we’ll deploy it as an OpenShift application and override the spring profile to use our _production_ values:

[source,sh,role="copypaste"]
----
oc new-app catalog -e JAVA_OPTS_APPEND='-Dspring.profiles.active=openshift' && oc expose service catalog && \
oc label dc/catalog app.kubernetes.io/part-of=catalog app.openshift.io/runtime=spring --overwrite && \
oc label dc/catalog-database app.kubernetes.io/part-of=catalog app.openshift.io/runtime=postgresql --overwrite && \
oc annotate dc/catalog app.openshift.io/connects-to=inventory,catalog-database --overwrite && \
oc annotate dc/catalog app.openshift.io/vcs-uri=https://github.com/RedHat-Middleware-Workshops/cloud-native-workshop-v2m4-labs.git --overwrite && \
oc annotate dc/catalog app.openshift.io/vcs-ref=ocp-4.3 --overwrite
----

Finally, make sure it’s actually done rolling out. Visit the {{ CONSOLE_URL }}/topology/ns/{{ USER_ID }}-cloudnativeapps[Topology View^] for the catalog, and ensure you get the blue circles!

image::inventory-catalog-topology.png[catalog, 700]

And then access the http://catalog-{{ USER_ID }}-cloudnativeapps.{{ ROUTE_SUBDOMAIN}}[Catalog Web frontend^] and ensure you get the expected inventory quantity (and not `-1`):

[NOTE]
====
Even if the rollout command reports success the application may not be ready yet and the reason for that is that we currently don’t have any liveness check configured, but we will add that in the next steps.
====

image::catalog.png[catalog, 700]

So now `Catalog` service is deployed to OpenShift. You can also see it in the Project Status in the OpenShift Console with running 4 pods such as catalog, catalog-database, inventory, and inventory-database.

=== 3. Developing and Deploying Shopping Cart Service

By now, you have deployed some of the essential elements for the Coolstore application. However, an online shop without a cart means no checkout experience. In this section, we are going to implement the Shopping Cart; in our Microservice world, we are going to call it the *cart service* and our java artifact/repo is called the *cart-service*.

The Cart service is RESTful and built with Quarkus using Red Hat’s Distributed _Data Grid_ technology. It stores all shopping cart data and assigns a unique id to each. It uses the Quarkus _Infinispan client_ to do this (_Infinispan_ is the name of the upstream project that Red Hat Data Grid is based on). The Shopping cart makes a call via the Quarkus REST client to fetch all items in the Catalog. In the end, Shopping cart also pushes messages to a _Kafka_ for each order, when the user is checking out. For that, we use the Quarkus Kafka client.

What is a _Shopping Cart_ in our context? A Shopping cart has a list of Shopping Items. Each item has a _quantity_, and other fields like discounts and promotional details. We will see these in more detail when we look at our model.

For this lab, we are using CodeReady Workspaces. Make sure you have the following project open in your workspace. Lets’s go through quickly how the cart service works and is built on _Quarkus_ Java runtimes. Go to _Explorer_ in CodeReady Workspaces and expand the *cart-service* directory.

image::codeready-workspace-cart-project.png[cart, 700]

We are going to use the Red Hat Distributed _Data Grid_ for caching all the users' carts.

Let's create a simple version of the *cache service* in our cluster. Open the Terminal in your CodeReady workspace and run the following command:

[source,sh,role="copypaste"]
----
oc new-app jboss/infinispan-server:10.0.0.Beta3 --name=datagrid-service
----

This will create a single instance of the Data Grid server to store our shopping carts.

Click on the {{ CONSOLE_URL }}/topology/ns/{{ USER_ID }}-cloudnativeapps[Topology View^] to see it.

Now that our cache service a.k.a datagrid-service is deployed. We want to ensure that everything in our cart is persisted in this blazing fast cache. It will help us when we have a few million users per second on a black Friday.

Following is what we need to do:

* Model our data
* Choose how we store the data
* Create a marshaller for our data
* Inject our cache connection into the service

We have made this choice easier for you. The default serialization is done using a library based on *protobuf*. We need to define the protobuf schema and a marshaller for each user type(s).

Let’s take a look at our `cart.proto` file in `cart-service/src/main/resources/META-INF`:

[source,java]
----
package coolstore;

message ShoppingCart {
  required double cartItemTotal = 1;
  required double cartItemPromoSavings = 2;
  required double shippingTotal = 3;
  required double shippingPromoSavings = 4;
  required double cartTotal = 5;
  required string cartId = 6;

  repeated ShoppingCartItem shoppingCartItemList = 7;
}

message ShoppingCartItem {
  required double price = 1;
  required int32 quantity = 2;
  required double promoSavings = 3;
  required Product product = 4;
}

// TODO ADD Product
message Promotion {
  required string itemId = 1;
  required double percentOff = 2;
}
----

* So our ShoppingCart has ShoppingCartItem
* ShoppingCartItem has Product

But we haven't defined the `Product` yet. Add this code to the `//TODO ADD Product` marker:

[source,java,role="copypaste"]
----
message Product {
  required string itemId = 1;
  required string name = 2;
  required string desc = 3;
  required double price = 4;
}
----

*Great!* Now we have the Product defined in our proto model. We should also ensure that this model also exists as *POJO*(Plain Old Java Object), that way our *REST Endpoint*, or *Cache* will be able to directly serialize and desrialize the data.

Next, open `Product.java` in `cart-service/src/main/java/com/redhat/cloudnative/model`:

[source,java]
----
    private String itemId;
    private String name;
    private String desc;
    private double price;
----

Notice that the entities match our proto file. The rest or Getters and Setters, so we can read and write data into them.

Let's go ahead and create a *Marshaller* for our Product class which will do exactly what we intend, read and write to our cache.

Create a new Java class called `ProductMarshaller.java` in `com.redhat.cloudnative.model` and copy the below code into the file:

[source,java,role="copypaste"]
----
package com.redhat.cloudnative.model;

import org.infinispan.protostream.MessageMarshaller;

import java.io.IOException;

public class ProductMarshaller implements MessageMarshaller<Product> {

    /*
     * Proto file specimen
     * message Product {
     * required string itemId = 1;
     * required string name = 2;
     * required string desc = 3;
     * required double price = 4;
     * }
     */

    @Override
    public Product readFrom(ProtoStreamReader reader) throws IOException {
        String itemId = reader.readString("itemId");
        String name = reader.readString("name");
        String desc = reader.readString("desc");
        double price = reader.readDouble("price");

        return new Product(itemId, name, desc, price);
    }

    @Override
    public void writeTo(ProtoStreamWriter writer, Product product) throws IOException {
        writer.writeString("itemId", product.getItemId());
        writer.writeString("name", product.getName());
        writer.writeString("desc", product.getDesc());
        writer.writeDouble("price", product.getPrice());
    }

    @Override
    public Class<? extends Product> getJavaClass() {
        return Product.class;
    }

    @Override
    public String getTypeName() {
        return "coolstore.Product";
    }

}
----

So now we have the capability to read from a *ProtoStream* and *Write* to it. And this will be done directly into our cache. We have already created the other model classes and mashallers, feel free to look around.

Now it's time to configure our *RemoteCache*, since its not embedded into our service. Open the `Producers.java` file in the `com.redhat.cloudnative` directory/package.

We use the producer to ensure our RemoteCache gets instantiated. We create methods called getCache and getConfigBuilder

* getConfigBuilder: sets up the basic cache config
* getCache, sets up our marshallers and proto files
* other config properties are injected at runtime

Add this code below the `// TODO Add getCache` and `// TODO add getConfigBuilder` marker:

[source,java,role="copypaste"]
----
    @Produces
    RemoteCache<String, ShoppingCart> getCache() throws IOException {

        RemoteCacheManager manager = new RemoteCacheManager(getConfigBuilder().build());

        SerializationContext serCtx = ProtoStreamMarshaller.getSerializationContext(manager);
        FileDescriptorSource fds = new FileDescriptorSource();
        fds.addProtoFiles("META-INF/cart.proto");
        serCtx.registerProtoFiles(fds);
        serCtx.registerMarshaller(new ShoppingCartMarshaller());
        serCtx.registerMarshaller(new ShoppingCartItemMarshaller());
        serCtx.registerMarshaller(new ProductMarshaller());
        serCtx.registerMarshaller(new PromotionMarhsaller());
        return manager.getCache();
    }

    protected ConfigurationBuilder getConfigBuilder() {
        ConfigurationBuilder cfg = null;
        cfg = new ConfigurationBuilder().addServer()
                .host(dgHost)
                .port(dgPort)
                .marshaller(new ProtoStreamMarshaller())
                .clientIntelligence(ClientIntelligence.BASIC);

        return cfg;

    }
----

*Perfect!* Now we have all the building blocks ready to use the cache. Let's start using our cache.

Next we need to make sure we will inject our cache in our service. Open `com.redhat.cloudnative.service.ShoppingCartServiceImpl` and add this at the `// TODO Inject RemoteCache` marker:

[source,java,role="copypaste"]
----
    @Inject
    @Remote("default")
    RemoteCache<String, ShoppingCart> carts;
----

The cart is quite simple; All the information from the browser i.e., via our *Angular App* is via _JSON_ at the _/api/cart_ endpoint:

* `GET /{cartId}` gets the items in the cart, or creates a new unique ID if one is not present.
* `POST /{cartId}/{itemId}/{quantity}` will add items to the cart.
* `DELETE /{cartId}/{itemId}/{quantity}` will remove items from the cart.
* `POST /checkout/{cartId}` will remove the items and invoke the checkout procedure.

Let’s take a look at how we do this with Quarkus. In our *cart-service* project and in our main package i.e., `com.redhat.cloudnative` is the `CartResource`. Let’s take a look at the getCart method.

At the `// TODO ADD getCart method` marker, add this method:

[source,java,role="copypaste"]
----
    public ShoppingCart getCart(@PathParam("cartId") String cartId) {
        return shoppingCartService.getShoppingCart(cartId);
    }
----

The code above is using the `ShoppingCartService`, which is injected into the `CartResource` via the Dependency Injection. The `ShoppingCartService` take a `cartId` as a parameter and returns the associated ShoppingCart. So that’s perfect, however, for our Endpoint i.e., CartResource to respond, we need to define a couple of things:

* The type of HTTPRequest
* The type of data it can receive
* The path it resolves too

Add the following code on top of the `getCart` method

[source,java,role="copypaste"]
----
    @GET
    @Produces(MediaType.TEXT_PLAIN)
    @Path("/{cartId}")
    @Operation(summary = "get the contents of cart by cartId")
----

We have now successfully stated that the method adheres to a GET request and accepts data in *plain text*. The path would be `/api/cart/{cartId}` finally, we add the `@Operation` annotation for some documentation, which is important for other developers using our service.

Take this opportunity to look at some of the other methods. You will find `@POST` and `@DELETE` and also the paths they adhere to. This is how we can construct a simple endpoint for our application.

[NOTE]
====
There are other *// TODO* markers and commented-out code we will use later. Leave them alone for now.
====

Build and deploy the project using the following command, which will use the maven plugin to deploy via CodeReady Workspaces Terminal:

[source,sh,role="copypaste"]
----
mvn clean package -DskipTests -f $CHE_PROJECTS_ROOT/cloud-native-workshop-v2m4-labs/cart-service
----

Create a build configuration for your application using OpenJDK base container image in OpenShift:

[source,sh,role="copypaste"]
----
oc new-build registry.access.redhat.com/redhat-openjdk-18/openjdk18-openshift:1.5 --binary --name=cart -l app=cart
----

Start and watch the build, which will take about minutes to complete:

[source,sh,role="copypaste"]
----
oc start-build cart --from-file $CHE_PROJECTS_ROOT/cloud-native-workshop-v2m4-labs/cart-service/target/*-runner.jar --follow
----

Deploy it as an OpenShift application after the build is done:

[source,sh,role="copypaste"]
----
oc new-app cart && oc expose svc/cart && \
oc label dc/cart app.kubernetes.io/part-of=cart app.openshift.io/runtime=java --overwrite && \
oc label dc/datagrid-service app.kubernetes.io/part-of=cart app.openshift.io/runtime=datagrid --overwrite && \
oc annotate dc/cart app.openshift.io/connects-to=catalog,datagrid-service --overwrite && \
oc annotate dc/cart app.openshift.io/vcs-uri=https://github.com/RedHat-Middleware-Workshops/cloud-native-workshop-v2m4-labs.git --overwrite && \
oc annotate dc/cart app.openshift.io/vcs-ref=ocp-4.3 --overwrite
----

Finally, make sure it’s actually done rolling out. Visit the {{ CONSOLE_URL }}/topology/ns/{{ USER_ID }}-cloudnativeapps[Topology View^] for the catalog, and ensure you get the blue circles!

image::cart-topology.png[catalog, 700]

And then access the http://cart-{{ USER_ID }}-cloudnativeapps.{{ ROUTE_SUBDOMAIN }}/swagger-ui[Cart Swagger UI^]:

image::cart-swagger-ui.png[cart, 700]

Notice that the documentation after the methods, this is an excellent way for other service developers to know what you intend to
do with each service method. You can try to invoke the methods and see the output from the service. Hence an excellent way to test
quickly as well.

=== 4. Developing and Deploying Order Service

The Order Service manages all orders when customers checkout items in the shopping cart. Lets’s go through quickly how the order
service get REST services to use the *MongoDB* database with *Quarkus* Java runtimes. Go to _Explorer: /projects_ in _CodeReady Workspaces_ Web IDE and expand *order-service* directory.

image::codeready-workspace-order-project.png[order, 700]

The application built in _Quarkus_ is quite simple: the user can add elements in a list using _RESTful APIs_ and the list is updated. All the information between the client and the server are formatted as *JSON*. The elements are stored in _MongoDB_.

Execute the following command for adding Maven Dependencies using Quarkus Extensions via CodeReady Workspaces Terminal:

[source,sh,role="copypaste"]
----
mvn quarkus:add-extension -Dextensions="resteasy-jsonb,mongodb-client" -f $CHE_PROJECTS_ROOT/cloud-native-workshop-v2m4-labs/order-service
----

You should see in the output:

[source,console]
----
✅ Adding extension io.quarkus:quarkus-resteasy-jsonb
✅ Adding extension io.quarkus:quarkus-mongodb-client
----

This command generates a Maven structure importing the RESTEasy/JAX-RS, JSON-B and MongoDB Client extensions. After this, the quarkus-mongodb-client extension has been added to your *pom.xml*.

image::order-pom-dependency.png[order, 700]

Before we create the order service using JSON REST service, let's have a look at the `Order` bean in `src/main/java/com/redhat/cloudnative/` as follows:

image::order_bean.png[order, 700]

Nothing fancy. One important thing to note is that having a default constructor is required by the *JSON serialization layer*.

Now, open the `com.redhat.cloudnative.OrderService` class -- it will be the business layer of our application and _store/load_ the orders from the MongoDB database. Add the following java code at each marker.

`// TODO: Inject MongoClient here` marker:

[source,java,role="copypaste"]
----
    @Inject MongoClient mongoClient;
----

Next, add this code below the `// TODO: Add a while loop to make an order lists using MongoCursor here` marker (in the `list()` method).

[source,java,role="copypaste"]
----
        MongoCursor<Document> cursor = getCollection().find().iterator();

        try {
            while (cursor.hasNext()) {
                Document document = cursor.next();
                Order order = new Order();
                order.setOrderId(document.getString("orderId"));
                order.setName(document.getString("name"));
                order.setTotal(document.getString("total"));
                order.setCcNumber(document.getString("ccNumber"));
                order.setCcExp(document.getString("ccExp"));
                order.setBillingAddress(document.getString("billingAddress"));
                order.setStatus(document.getString("status"));
                list.add(order);
            }
        } finally {
            cursor.close();
        }
----

Next, add this code below the `// TODO: Add to create a Document based order here` marker in `add(Order order)` method:

[source,java,role="copypaste"]
----
        Document document = new Document()
                .append("orderId", order.getOrderId())
                .append("name", order.getName())
                .append("total", order.getTotal())
                .append("ccNumber", order.getCcNumber())
                .append("ccExp", order.getCcExp())
                .append("billingAddress", order.getBillingAddress())
                .append("status", order.getStatus());
        getCollection().insertOne(document);
----

These two methods convert between a `Document` object suitable for use with MongoDB and the `Order` document which is our business value object.

Now, edit the `com.redhat.cloudnative.OrderResource` class as follows in each marker:

`// TODO: Add JAX-RS annotations here` marker:

[source,java,role="copypaste"]
----
@Path("/api/orders")
@Produces(MediaType.APPLICATION_JSON)
@Consumes(MediaType.APPLICATION_JSON)
----

`// TODO: Inject OrderService here` marker:

[source,java,role="copypaste"]
----
    @Inject OrderService orderService;
----

`// TODO: Add list(), add(), updateStatus() methods here` marker:

[source,java,role="copypaste"]
----
    @GET
    public List<Order> list() {
        return orderService.list();
    }

    @POST
    public List<Order> add(Order order) {
        orderService.add(order);
        return list();
    }

    @GET
    @Path("/{orderId}/{status}")
    public List<Order> updateStatus(@PathParam("orderId") String orderId, @PathParam("status") String status) {
        orderService.updateStatus(orderId, status);
        return list();
    }
----

The implementation is pretty straightforward and you just need to define your endpoints using the *JAX-RS annotations* and use the _OrderService_ to list/add new orders.

The main property to configure is the URL to access to *MongoDB*, almost all configuration can be included in the connection URI
so we advise you to do so, you can find more information in the
https://docs.mongodb.com/manual/reference/connection-string/[MongoDB documentation^]

Open `application.properties` in `src/main/resources/` and add the following configuration:

[source,sh,role="copypaste"]
----
quarkus.mongodb.connection-string = mongodb://order-database:27017
----

By using a Bson *Codec*, the MongoDB Client will take care of the transformation of your domain object to/from a MongoDB *Document* automatically.

First you need to create a Bson Codec that will tell Bson how to transform your entity to/from a MongoDB Document. Here we use a _CollectibleCodec_ as our object is retrievable from the database (it has a MongoDB identifier), if not we would have used a _Codec_ instead. More information in the https://mongodb.github.io/mongo-java-driver/3.10/bson/codecs[codec
documentation^].

Edit the `com.redhat.cloudnative.codec.OrderCodec` class as follows:

`// TODO: Add Encode & Decode contexts here` marker:

[source,java,role="copypaste"]
----
    @Override
    public void encode(BsonWriter writer, Order Order, EncoderContext encoderContext) {
        Document doc = new Document();
        doc.put("orderId", Order.getOrderId());
        doc.put("name", Order.getName());
        doc.put("total", Order.getTotal());
        doc.put("ccNumber", Order.getCcNumber());
        doc.put("ccExp", Order.getCcExp());
        doc.put("billingAddress", Order.getBillingAddress());
        doc.put("status", Order.getStatus());
        documentCodec.encode(writer, doc, encoderContext);
    }

    @Override
    public Class<Order> getEncoderClass() {
        return Order.class;
    }

    @Override
    public Order generateIdIfAbsentFromDocument(Order document) {
        if (!documentHasId(document)) {
            document.setOrderId(UUID.randomUUID().toString());
        }
        return document;
    }

    @Override
    public boolean documentHasId(Order document) {
        return document.getOrderId() != null;
    }

    @Override
    public BsonValue getDocumentId(Order document) {
        return new BsonString(document.getOrderId());
    }

    @Override
    public Order decode(BsonReader reader, DecoderContext decoderContext) {
        Document document = documentCodec.decode(reader, decoderContext);
        Order order = new Order();
        if (document.getString("orderId") != null) {
            order.setOrderId(document.getString("orderId"));
        }
        order.setName(document.getString("name"));
        order.setTotal(document.getString("total"));
        order.setCcNumber(document.getString("ccNumber"));
        order.setCcExp(document.getString("ccExp"));
        order.setBillingAddress(document.getString("billingAddress"));
        order.setStatus(document.getString("status"));
        return order;
    }
----

Then you need to create a `CodecProvider` to link this `Codec` to the Order class.

Edit the `com.redhat.cloudnative.codec.OrderCodecProvider` class as follows:

`// TODO: Add Codec get method here` marker:

[source,java,role="copypaste"]
----
    @Override
    public <T> Codec<T> get(Class<T> clazz, CodecRegistry registry) {
        if (clazz == Order.class) {
            return (Codec<T>) new OrderCodec();
        }
        return null;
    }
----

_Quarkus_ will register the _CodecProvider_ for you.

Finally, when getting the _MongoCollection_ from the database you can use directly the Order class instead of the Document one, the codec will automatically map the Document to/from your Order class.

Edit the `com.redhat.cloudnative.CodecOrderService` class as follows:

`// TODO: Add MongoCollection method here` marker:

[source,java,role="copypaste"]
----
    private MongoCollection<Order> getCollection(){
        return mongoClient.getDatabase("order").getCollection("order", Order.class);
    }
----

Build and deploy the project using the following command, which will use the maven plugin to deploy via CodeReady Workspaces Terminal:

[source,sh,role="copypaste"]
----
mvn clean package -DskipTests -f $CHE_PROJECTS_ROOT/cloud-native-workshop-v2m4-labs/order-service
----

Run the following `oc` command to deploy a `MongoDB` to OpenShift via CodeReady Workspaces Terminal:

[source,sh,role="copypaste"]
----
oc new-app -n {{ USER_ID }}-cloudnativeapps --docker-image mongo:4.0 --name=order-database
----

Once the MongoDB is deployed successfully, create a build configuration for your application using OpenJDK base container image in OpenShift:

[source,sh,role="copypaste"]
----
oc new-build registry.access.redhat.com/redhat-openjdk-18/openjdk18-openshift:1.5 --binary --name=order -l app=order
----

Start and watch the build, which will take about minutes to complete:

[source,sh,role="copypaste"]
----
oc start-build order --from-file=$CHE_PROJECTS_ROOT/cloud-native-workshop-v2m4-labs/order-service/target/order-1.0-SNAPSHOT-runner.jar --follow
----

Deploy it as an OpenShift application after the build is done:

[source,sh,role="copypaste"]
----
oc new-app order && oc expose svc/order && \
oc label dc/order app.kubernetes.io/part-of=order app.openshift.io/runtime=java --overwrite && \
oc label dc/order-database app.kubernetes.io/part-of=order app.openshift.io/runtime=mongodb --overwrite && \
oc annotate dc/order app.openshift.io/connects-to=order-database --overwrite && \
oc annotate dc/order app.openshift.io/vcs-uri=https://github.com/RedHat-Middleware-Workshops/cloud-native-workshop-v2m4-labs.git --overwrite && \
oc annotate dc/order app.openshift.io/vcs-ref=ocp-4.3 --overwrite
----

Finally, make sure it’s actually done rolling out. Visit the {{ CONSOLE_URL }}/topology/ns/{{ USER_ID }}-cloudnativeapps[Topology View^] for the orders. Ensure you get the blue circles!

image::order-topology.png[order, 700]

And then access the http://order-{{ USER_ID }}-cloudnativeapps.{{ ROUTE_SUBDOMAIN}}/api/orders[Orders^]. You will see empty result because you didn’t add any shopping items yet:

[source,sh]
----
[]
----

You can also see this with `curl` with this command in a Terminal:

[source,sh,role="copypaste"]
----
curl -s http://order-{{USER_ID}}-cloudnativeapps.{{ROUTE_SUBDOMAIN}}/api/orders | jq
----

Which will also return an empty array `[]`.

=== 5. Deploying WEB-UI Service

Our Web UI serves a frontend based on https://angularjs.org/[AngularJS^] and http://patternfly.org/[PatternFly^] running in a https://access.redhat.com/documentation/en/openshift-container-platform/3.3/paged/using-images/chapter-2-source-to-image-s2i[Node.js] container. https://www.redhat.com/en/products/runtimes[Red Hat Runtimes^] includes *Node.js* support along with other runtimes used for cloud native development.

Lets’s go through quickly how the frontend service works and is built on Node.js runtimes. Go to _Explorer: /projects_ in CodeReady Workspaces and expand the `coolstore-ui` directory.

image::codeready-workspace-coolstore-ui.png[coolstore-ui, 700]

You will see javascript for specific cloud-native services such as the cart, catatlog, and order service as above.

Now, we will deploy a presentation layer to OpenShift cluster using https://www.npmjs.com/package/nodeshift[Nodeshift] command line tool, a programmable API that you can use to deploy Node.js projects to OpenShift.

Install Nodeshift via the CodeReady Workspaces Terminal:

[source,sh,role="copypaste"]
----
cd $CHE_PROJECTS_ROOT/cloud-native-workshop-v2m4-labs/coolstore-ui && npm install --save-dev nodeshift
----

Deploy the coolstore-ui service using `Nodeshift` in a CodeReady Workspaces Terminal. It will take a minute to complete the deployment:

[source,sh,role="copypaste"]
----
npm run nodeshift && oc expose svc/coolstore-ui && \
oc label dc/coolstore-ui app.kubernetes.io/part-of=coolstore --overwrite && \
oc annotate dc/coolstore-ui app.openshift.io/connects-to=order-cart,catalog,inventory,order --overwrite && \
oc annotate dc/coolstore-ui app.openshift.io/vcs-uri=https://github.com/RedHat-Middleware-Workshops/cloud-native-workshop-v2m4-labs.git --overwrite && \
oc annotate dc/coolstore-ui app.openshift.io/vcs-ref=ocp-4.3 --overwrite
----

Back on the {{ CONSOLE_URL }}/topology/ns/{{ USER_ID }}-cloudnativeapps[Topology View^], make sure it's done deploying (dark blue circle):

image::coolstore-ui_topology.png[coolstore-ui, 700]

And then access the http://coolstore-ui-{{ USER_ID }}-cloudnativeapps.{{ ROUTE_SUBDOMAIN}}[Red Hat Cool Store^] and ensure you get the expected products and inventories:

image::web-ui-landing.png[coolstore-ui, 700]

This confirms that the frontend is properly hooked up to the backend, which is properly hooked up to our Data Grid deployment.

=== Summary

In this scenario we developed and deployed 5 microservices, each with a REST API and each of which communicate with the other microservices. We also used a variety of application runtimes such as Quarkus, Spring Boot, and Node.js to compile, package, and containerize applications -- this is an important capability of advanced cloud-native architectures.

To deploy cloud-native applications with multiple datasources on an OpenShift cluster, Quarkus provides an easy way to connect multiple datasources and obtain a reference to those datasources such as PostgreSQL and MongoDB in code.

In the end, we optimized the _transaction performance_ of the shopping cart service by integrating it with *Red Hat Data Grid* to increase end users’ (customers) satification. This may not be obvious with only one user (you), but at scale these components can ensure relability and business performance. *Congratulations!*
